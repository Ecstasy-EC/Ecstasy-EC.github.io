---
title: "Temporal Overlapping Prediction: A Self-supervised Pre-training Method for LiDAR Moving Object Segmentation"
collection: publications
permalink: /publication/2025-06-25-TOP
excerpt: 'Moving object segmentation (MOS) on LiDAR point clouds is crucial for autonomous systems like self-driving vehicles. Previous supervised approaches ...'
date: 2025-06-25
venue: 'International Conference on Computer Vision (ICCV 2025)'
paperurl: 'https://arxiv.org/abs/2503.07167'
paperurltext: '[pdf]'
paperbibtex: 'https://scholar.googleusercontent.com/scholar.bib?q=info:-2YRa44moxgJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgIZ17YeELusyB4ESLs:AAZF9b8AAAAAaNgCULtrXWTKHuPDAWBSPLETANM&amp;scisig=AAZF9b8AAAAAaNgCUOPiHV8kyx2nK-azrYoLw_Q&amp;scisf=4&amp;ct=citation&amp;cd=-1'
citation: 'Miao, Z., Chen, R., Cai, Y., He, B., Zhao, W., Shao, W., ... &amp; Zhang, F. (2025). Temporal Overlapping Prediction: A Self-supervised Pre-training Method for LiDAR Moving Object Segmentation. in <i>ICCV 2025</i>.'
---
## Abstract

Moving object segmentation (MOS) on LiDAR point clouds is crucial for autonomous systems like self-driving vehicles. Previous supervised approaches rely heavily on costly manual annotations, while LiDAR sequences naturally capture temporal motion cues that can be leveraged for self-supervised learning. In this paper, we propose Temporal Overlapping Prediction (TOP), a self-supervised pre-training method that alleviate the labeling burden for MOS. TOP explores the temporal overlapping points that commonly observed by current and adjacent scans, and learns spatiotemporal representations by predicting the occupancy states of temporal overlapping points. Moreover, we utilize current occupancy reconstruction as an auxiliary pre-training objective, which enhances the current structural awareness of the model. We conduct extensive experiments and observe that the conventional metric Intersection-over-Union (IoU) shows strong bias to objects with more scanned points, which might neglect small or distant objects. To compensate for this bias, we introduce an additional metric called mIoU_obj to evaluate object-level performance. Experiments on nuScenes and SemanticKITTI show that 	extbf{TOP} outperforms both supervised training-from-scratch baseline and other self-supervised pre-training baselines by up to 28.77% relative improvement, demonstrating strong transferability across LiDAR setups and generalization to other tasks. Code and pre-trained models will be publicly available upon publication.
